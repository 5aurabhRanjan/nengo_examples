{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an Autoencoder With TensorNodes\n",
    "\n",
    "When working with TensorNodes you can train them just like normal parts of a Nengo model. The only deviation from the standard procedure is the definition of the custom classes which encapsulate the Tensorflow portions. \n",
    "\n",
    "In this example we will illustrate this trainability by training an autoencoder on the MNIST dataset. The autoencoder takes the input in with a dimensionality of `784` (28\\*28) and reduces it to a dimensionality of `128`. This is the encoding phase where the network is effectively compressing the input. The decode phase then takes that `128` dimension representation and attempts to reconstruct the original input with it.\n",
    "\n",
    "We shown at the bottom of the notebook how the training changes the output. The output starts off as pure noise and gradually looks more and more like the input. Culminating with easily identifiable reconstructions. The training of this network took ~30 minutes on a _Quadro M4000 GPU_, so although not infeasible to go through the training yourself a pretrained model is available for your convenience. To enable the loading of the pretrained model simply set the `LOADING` flag to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "LOADING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network architecture consists of one input layer followed by 4 densly connected layers. The layers architecture is mirrored such that:\n",
    "\n",
    "```\n",
    "Layer 1: 784 Elements - Input\n",
    "\n",
    "Layer 2: 256 Elements - Encode 1\n",
    "\n",
    "Layer 3: 128 Elements - Encode 2\n",
    "\n",
    "Layer 4: 256 Elements - Decode 1\n",
    "\n",
    "Layer 5: 784 Elements - Decode 2/Output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer num features\n",
    "n_hidden_2 = 128 # 2nd layer num features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorNodes are broken up into two classes, an Encoder, which compresses the input; and a Decoder, which decompresses the output to attempt to recreate the original.\n",
    "\n",
    "Both of the TensorNode types consist of two fully connected (dense) layers which are in turn connected to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "class Encoder(object):\n",
    "    def pre_build(self, shape_in, shape_out):\n",
    "        self.n_mini = shape_in[0]\n",
    "        self.size_in = shape_in[1]\n",
    "        self.size_out = shape_out[1]\n",
    "        \n",
    "    \n",
    "    def __call__(self, t, x):    \n",
    "        dense = tf.contrib.layers.fully_connected(x, n_hidden_1)\n",
    "        dense = tf.contrib.layers.fully_connected(dense, n_hidden_2)\n",
    "\n",
    "        return dense\n",
    "\n",
    "\n",
    "# Building the encoder\n",
    "class Decoder(object):\n",
    "    def pre_build(self, shape_in, shape_out):\n",
    "        self.n_mini = shape_in[0]\n",
    "        self.size_in = shape_in[1]\n",
    "        self.size_out = shape_out[1]\n",
    "    \n",
    "    def __call__(self, t, x):    \n",
    "        dense = tf.contrib.layers.fully_connected(x, n_hidden_1)\n",
    "        dense = tf.contrib.layers.fully_connected(dense, self.size_out)\n",
    "\n",
    "        return dense\n",
    "\n",
    "\n",
    "with nengo.Network() as net:\n",
    "     # create node to feed in images\n",
    "    inp = nengo.Node(nengo.processes.PresentInput(mnist.test.images, 0.001*10))\n",
    "    \n",
    "    # create TensorNodes to insert into the network\n",
    "    tf_encode = nengo_dl.TensorNode(Encoder(), size_in=28 * 28, size_out=n_hidden_2, label='H1')\n",
    "    tf_decode = nengo_dl.TensorNode(Decoder(), size_in=n_hidden_2, size_out=n_input, label='H2')\n",
    "    \n",
    "    # connecting all the nodes together\n",
    "    nengo.Connection(inp, tf_encode)\n",
    "    nengo.Connection(tf_encode, tf_decode)\n",
    "    \n",
    "    # defining probes\n",
    "    input_probe = nengo.Probe(inp)\n",
    "    output_probe = nengo.Probe(tf_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for this network the training data for output and input are the same, therefore the same data can be used for both. We utilize Nengo's built in `PresentInput` method to pass in the MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(steps, batchsize, pos):\n",
    "    # defining the training data\n",
    "    test_in_data = []\n",
    "    test_out_data = []\n",
    "    outputs = []\n",
    "    output_array = []\n",
    "    input_array = []\n",
    "    for k in range(batchsize):\n",
    "        input_array.append(nengo.processes.PresentInput(mnist.train.images[pos + k:], 0.001*steps).run(0.001*steps))\n",
    "    in_dict = {inp:np.asarray(input_array)}\n",
    "    out_dict = {output_probe:np.asarray(input_array)}\n",
    "    return in_dict, out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the network you first break the dataset up into batches of 64 images, then feed those batches into the network. You repeat this process for a set amount of repetitions (runs through the dataset). The amount of repetitions can be modified at your discretion, but it was found that 15 gives results which are allowable (more repetitions would result in a more accurate output at the cost of an increased training time, to a point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_examples = 64\n",
    "n_iters = int(55000/(n_examples))\n",
    "losses = []\n",
    "start_time = time.time()\n",
    "round_time = 0\n",
    "learning_rate = 0.05\n",
    "steps = 10\n",
    "counted = 0\n",
    "delta = 1\n",
    "repetitions = 15\n",
    "with nengo_dl.Simulator(net, step_blocks=steps, minibatch_size=n_examples) as sim:\n",
    "    if LOADING:\n",
    "        # Running an example through the network so the difference of training is shown\n",
    "        input_dict, output_dict = gen_data(steps, n_examples, 0)\n",
    "        losses.append(sim.loss(input_dict, output_dict, 'mse'))\n",
    "        sim.run(0.001*steps)\n",
    "        param_path = os.path.join(\"nengo_autoencoder\", \"Nengo-Autoencoder\")\n",
    "        # Checking if parameters are already downloaded, if not retrieve them\n",
    "        if not os.path.exists(\"nengo_autoencoder\"):\n",
    "            os.mkdir(\"nengo_autoencoder\")\n",
    "        if not os.path.exists(param_path + \".index\"):\n",
    "            param_zip_path = os.path.join(\"nengo_autoencoder\", \"nengo-autoencoder-params.zip\")\n",
    "            urlretrieve(\"https://github.com/clvcooke/nengo_dl/raw/master/docs/examples/Nengo-Autoencoder-Weights.zip\", param_zip_path)\n",
    "            with zipfile.ZipFile(param_zip_path) as f:\n",
    "                f.extractall(\"nengo_autoencoder\")\n",
    "            os.remove(param_zip_path)\n",
    "        sim.load_params(param_path)\n",
    "    else:\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "        for e in range(repetitions):\n",
    "            input_dict, output_dict = gen_data(steps, n_examples, 0)\n",
    "            losses.append(sim.loss(input_dict, output_dict, 'mse'))\n",
    "            print(losses)\n",
    "\n",
    "            if counted>0:\n",
    "                old_delta = delta\n",
    "                delta = losses[counted] - losses[counted-1]\n",
    "                print(\"delta: \" +str(losses[counted] - losses[counted-1]) )\n",
    "            sim.run(0.001*steps)\n",
    "            counted = counted + 1\n",
    "            for i in range(n_iters):\n",
    "                print(str(i+1) + \"/\" + str(n_iters))\n",
    "                input_dict, output_dict = gen_data(steps, n_examples, n_examples*i)\n",
    "                sim.train(input_dict,\n",
    "                         output_dict,\n",
    "                         optimizer,\n",
    "                         n_epochs=2)\n",
    "                round_time = (round_time*(i) + time.time() - start_time) / (i+1)\n",
    "                start_time = time.time()\n",
    "                print(\"ETA: ~\" + str(round_time*((10-e)*n_iters - i-1)/60) + \" minutes\")\n",
    "    losses.append(sim.loss(input_dict, output_dict, 'mse'))\n",
    "    print(losses)\n",
    "    if counted>0:\n",
    "        print(\"delta: \" +str(losses[counted] - losses[counted-1]) )\n",
    "    sim.run(0.001*steps)\n",
    "    counted = counted + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the input on the top row, then the reconstructed output on the bottom. We can see that as training progresses (moving left to right) the reconstructions become more and more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(2, len(losses), figsize=(len(losses),2))\n",
    "for i in range(0, len(losses)):\n",
    "    axis[0][i].imshow(np.reshape(sim.data[input_probe][0][i*steps+steps-1], (28, 28)))\n",
    "    axis[1][i].imshow(np.reshape(sim.data[output_probe][0][i*steps+steps-1], (28, 28)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
